{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4850c241-205e-493e-aa12-f4ff90d84902",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bank Transaction Monitoring & Data Pipeline Simulation project using Spark SQL\n",
    "## Objective:\n",
    "To build a scalable data pipeline that ingests raw bank transactions, transforms them using Spark SQL, and analyzes them to detect potential fraudulent behavior. The goal is to demonstrate end-to-end ETL and analytics on large-scale financial data using Spark SQL in Databricks.\n",
    "## Tools & Technologies Used:\n",
    "- Databricks (Runtime 12.2 LTS)\n",
    "- Apache Spark 3.3.2\n",
    "- Spark SQL\n",
    "- PySpark (for ETL)\n",
    "- CSV File (Simulated banking transactions)\n",
    "\n",
    "## Dataset Description:\n",
    "The dataset contains fields like:\n",
    "\n",
    "step: Time step of the transaction\n",
    "\n",
    "type: Transaction type (PAYMENT, TRANSFER, etc.)\n",
    "\n",
    "amount: Amount transacted\n",
    "\n",
    "nameOrig, nameDest: Sender & receiver IDs\n",
    "\n",
    "oldbalanceOrg, newbalanceOrig: Sender's balance before & after\n",
    "\n",
    "oldbalanceDest, newbalanceDest: Receiver's balance before & after\n",
    "\n",
    "isFraud: Fraud indicator\n",
    "\n",
    "isFlaggedFraud: Flagged as suspicious by system\n",
    "\n",
    "## Business Context:\n",
    "Banks and financial institutions process millions of transactions daily. Identifying suspicious patterns in real-time is critical for fraud prevention. This project simulates a data engineering pipeline where raw banking transactions are ingested, cleaned, analyzed, and used to highlight fraud trends.\n",
    "## Why Spark SQL and Databricks?\n",
    "Scalability: Handles large datasets efficiently with distributed computing.\n",
    "\n",
    "Speed: In-memory processing provides faster transformations than traditional SQL engines.\n",
    "\n",
    "Ease of Use: Spark SQL syntax is similar to SQL, making it beginner-friendly for data analysis and transformation.\n",
    "\n",
    "Integrated Workspace: Databricks allows you to develop notebooks, run Spark jobs, and manage clusters—all in one place.\n",
    "\n",
    "Industry-Relevant: Spark + Databricks is widely used in top tech and finance companies for real-time fraud detection, stream processing, and data engineering.\n",
    "## Three-Layer Architecture:\n",
    "Ingestion Layer: Collects raw data from various sources and loads it into the data pipeline.\n",
    "\n",
    "Processing Layer: Cleans, transforms, and enriches the raw data, preparing it for analysis.\n",
    "\n",
    "Service Layer: Provides processed and aggregated data in an accessible format for consumption by applications or users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f04763d7-e664-4d4f-a7cb-1b0b9996268f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.Ingestion Layer (Raw Data Inflow)\n",
    "#### Goal: Bring raw transactional data into Databricks for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f10586f3-6dbd-4ae2-88dc-49c20a8f5565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Upload raw CSV  to Databricks FileStore\n",
    "raw_df = spark.read.csv(\"dbfs:/FileStore/shared_uploads/bh.shreya99@gmail.com/banking_transaction_data.csv\", header=True, inferSchema=True)\n",
    "raw_df.show(5)\n",
    "#Read the data using Spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12766bc9-9f81-47c6-8056-2bcc50c84356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Temporary View:\n",
    "raw_df.createOrReplaceTempView(\"transactions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9f25d4d-010a-478c-a894-ee9b9126b7a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "\n",
    "This command creates a temporary SQL table named transactions from the DataFrame df.\n",
    "This step is needed to run SQL queries on the DataFrame using Spark SQL in Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bce54dd-83e3-49fa-a0cf-ae6c72b70c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Processing Layer (Data Cleaning, Transformation, Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5894db32-61cb-4259-a9c6-150d68991291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1: Data Cleaning (Null & Duplicate Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4713669-23f2-46e8-b0b2-17570d747e0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n|step|type|amount|nameOrig|oldbalanceOrg|newbalanceOrig|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n|   0|   0|     0|       0|            0|             0|       0|             0|             0|      0|             0|\n+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n\n+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+-----+\n|step|type|amount|nameOrig|oldbalanceOrg|newbalanceOrig|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|count|\n+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+-----+\n+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Null Check\n",
    "from pyspark.sql.functions import col, when, count\n",
    "raw_df.select([count(when(col(c).isNull(), c)).alias(c) for c in raw_df.columns]).show()\n",
    "\n",
    "# Duplicate Check\n",
    "raw_df.groupBy(raw_df.columns).count().filter(\"count > 1\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b284c838-bad4-4004-9f7e-5c7dc65af0be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "\n",
    "This dataset is complete — there are no missing or blank entries in any of the columns like step, amount, nameOrig, isFraud, etc.\n",
    "\n",
    "Again, the dataset has no exact duplicate rows. Every row is unique based on all columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cd425dc-0ffd-4436-be8c-c3ff58fec875",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Understanding Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57ba7a73-59bf-4d81-9feb-bc35a9aa8d0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- step: integer (nullable = true)\n |-- type: string (nullable = true)\n |-- amount: double (nullable = true)\n |-- nameOrig: string (nullable = true)\n |-- oldbalanceOrg: double (nullable = true)\n |-- newbalanceOrig: double (nullable = true)\n |-- nameDest: string (nullable = true)\n |-- oldbalanceDest: double (nullable = true)\n |-- newbalanceDest: double (nullable = true)\n |-- isFraud: integer (nullable = true)\n |-- isFlaggedFraud: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "raw_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8ca5761-dd9a-44be-8e82-10bedcc4f492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step3: Total Transaction:Understand overall volume of transaction records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "698e94d3-63ac-4593-98f0-892b34d755f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|total_transactions|\n+------------------+\n|           1048575|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS total_transactions FROM transactions\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb78e6b0-280e-47b1-b259-621bcf0d2fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "This table shows that there are a total of 1,048,575 transactions, indicating a large dataset suitable for robust analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baa03e9b-3635-4797-864e-0424e20cb71b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Transaction types summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f3c1dab-80f1-41b6-ad02-01aef8c1dea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n|    type| count|\n+--------+------+\n|CASH_OUT|373641|\n| PAYMENT|353873|\n| CASH_IN|227130|\n|TRANSFER| 86753|\n|   DEBIT|  7178|\n+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT type, COUNT(*) AS count\n",
    "    FROM transactions\n",
    "    GROUP BY type\n",
    "    ORDER BY count DESC\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2940b59-25f0-4798-87ee-1a60f7ef6b1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "This step will analyze how many transactions are there for each type (like PAYMENT, TRANSFER, etc.).\n",
    "\n",
    "This table displays the counts of different transaction types, revealing that CASH_OUT and PAYMENT are the most frequent, while DEBIT transactions are significantly less common.\n",
    "CASH_OUT and PAYMENT are the most frequent transaction types, suggesting they play a major role in overall transaction volume and may require closer monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "247608e0-0df0-450c-8cbb-68543edc1bed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Total Amount Transacted per Type: Understand financial impact of each transaction type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9649fc66-fca3-4594-8437-aa3ba5154ab2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n|    type|     total_amount|\n+--------+-----------------+\n|CASH_OUT|6.876473738324E10|\n|TRANSFER|5.503643567413E10|\n| CASH_IN|3.859475828889E10|\n| PAYMENT|  3.93609652216E9|\n|   DEBIT|    4.219599495E7|\n+--------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Execute the Spark SQL query\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT type, \n",
    "           ROUND(SUM(amount), 2) AS total_amount \n",
    "    FROM transactions \n",
    "    GROUP BY type \n",
    "    ORDER BY total_amount DESC\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "result.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15da4679-3273-43b8-8969-e7ba82f83fb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### Interpretation:\n",
    "This table displays the total aggregated amounts for each transaction type, showing that CASH_OUT and TRANSFER involve significantly higher sums of money compared to other transaction types like DEBIT and PAYMENT.\n",
    "\n",
    "CASH_OUT and TRANSFER are the dominant transaction types, indicating potential areas to focus fraud detection and resource allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "206c9a8f-224c-43f3-bbf6-e5c264155438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6: Fraud Detection Summary: Identify which transaction types are most vulnerable to fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f31fb7-11e8-466a-9222-71b92cba89ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+\n|    type| total|frauds|\n+--------+------+------+\n|TRANSFER| 86753|   564|\n| CASH_IN|227130|     0|\n|CASH_OUT|373641|   578|\n| PAYMENT|353873|     0|\n|   DEBIT|  7178|     0|\n+--------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT type, \n",
    "           COUNT(*) AS total, \n",
    "           SUM(isFraud) AS frauds \n",
    "    FROM transactions \n",
    "    GROUP BY type\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c6a6b2b-1c9d-4229-a899-541123c63ea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Interpretation:\n",
    "This table shows the total count and the number of fraudulent transactions for each transaction type, indicating that only TRANSFER and CASH_OUT types contain fraudulent activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ce979c2-366d-4551-94f0-e595df7e82bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 7:  Flagged Frauds vs Actual Frauds: Compare system's flagged frauds vs real frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d78220b0-9488-43c3-947c-79ed9550b9fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n|actual_frauds|flagged_frauds|\n+-------------+--------------+\n|         1142|             0|\n+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "      SUM(CASE WHEN isFraud = 1 THEN 1 ELSE 0 END) AS actual_frauds,\n",
    "      SUM(CASE WHEN isFlaggedFraud = 1 THEN 1 ELSE 0 END) AS flagged_frauds\n",
    "    FROM transactions\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b708f30a-c2da-4820-8c18-0cc4265c8826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "The table indicates a significant problem: there are 1,142 instances of actual fraud, but the existing system, which should flag fraudulent transactions, has identified zero of them. This means the current fraud detection mechanism is completely ineffective in catching these fraudulent activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1911ee8-62ed-4c37-8afb-8bbb45eb0eee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 8: High-Value Fraudulent Transactions: Investigate top high-risk transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0c69813-1dd7-4912-be60-424e87cad1a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+-----------+----+\n|    type|amount|   nameOrig|   nameDest|step|\n+--------+------+-----------+-----------+----+\n|TRANSFER| 1.0E7| C792651637| C397396936|  84|\n|CASH_OUT| 1.0E7| C351297720| C766681183|   4|\n|CASH_OUT| 1.0E7|  C29118015|C1379703840|  33|\n|TRANSFER| 1.0E7|   C7162498| C945327594|   4|\n|TRANSFER| 1.0E7| C416779475| C380259496|  19|\n|TRANSFER| 1.0E7|C1439740840| C875288652|  33|\n|CASH_OUT| 1.0E7|C1079335762| C615227407|  82|\n|CASH_OUT| 1.0E7|C2050703310|C1622860679|  19|\n|TRANSFER| 1.0E7|  C53057884| C588547519|  72|\n|CASH_OUT| 1.0E7|C1438388258|C1089455271|  72|\n+--------+------+-----------+-----------+----+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT type, amount, nameOrig, nameDest, step\n",
    "    FROM transactions\n",
    "    WHERE isFraud = 1 AND amount > 200000\n",
    "    ORDER BY amount DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3905bf6-4e5b-4a56-bbed-91968a23aba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "This query highlights the top 10 high-value fraud transactions, helping to detect major fraud attempts based on amount.\n",
    "\n",
    "High-value fraudulent transactions predominantly occur via TRANSFER and CASH_OUT methods, indicating these types are prime targets for large-scale fraud in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8528505-8aa9-4bf9-92de-698b8c0716ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 9: Account Balance Anomalies in Fraud Cases: Spot cases where funds were not credited to destination — suspicious behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e64cc782-0ede-4125-a0e8-e5d4eecf6eef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+----------+----------+----------+\n|    type|total_fraud_cases|avg_amount|max_amount|min_amount|\n+--------+-----------------+----------+----------+----------+\n|TRANSFER|              542|1229479.35|     1.0E7|     119.0|\n|CASH_OUT|                1|   82806.2|   82806.2|   82806.2|\n+--------+-----------------+----------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "insightful_fraud = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    type,\n",
    "    COUNT(*) AS total_fraud_cases,\n",
    "    ROUND(AVG(amount), 2) AS avg_amount,\n",
    "    MAX(amount) AS max_amount,\n",
    "    MIN(amount) AS min_amount\n",
    "FROM transactions\n",
    "WHERE isFraud = 1 AND oldbalanceDest = 0 AND newbalanceDest = 0\n",
    "GROUP BY type\n",
    "ORDER BY total_fraud_cases DESC\n",
    "\"\"\")\n",
    "\n",
    "insightful_fraud.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7f25e5f-f42e-43d4-ba54-6b27f9937477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Interpretation:\n",
    "This analysis shows the frequency and scale of fraudulent transactions where the destination account remained uncredited (possibly indicating fake accounts or failed transfers). Most of these were high-value TRANSFER and CASH_OUT transactions.\n",
    "\n",
    "This table reveals that while TRANSFER transactions account for almost all fraud cases (542 vs. 1), they also exhibit a wide range of fraudulent amounts, including extremely high values (1.0×10 \n",
    "7\n",
    " ), whereas the single CASH_OUT fraud case has a fixed amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81a5be85-34f9-444d-8bd6-7ff9636b42ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Serving Layer (Insights Sharing / Dashboard / Reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbf862e7-63fb-4b06-993c-0157514d1d76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Transaction Type Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a971eec-5620-40b7-be4c-01c2eb99d15c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>type</th><th>count</th></tr></thead><tbody><tr><td>TRANSFER</td><td>86753</td></tr><tr><td>CASH_IN</td><td>227130</td></tr><tr><td>CASH_OUT</td><td>373641</td></tr><tr><td>PAYMENT</td><td>353873</td></tr><tr><td>DEBIT</td><td>7178</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "TRANSFER",
         86753
        ],
        [
         "CASH_IN",
         227130
        ],
        [
         "CASH_OUT",
         373641
        ],
        [
         "PAYMENT",
         353873
        ],
        [
         "DEBIT",
         7178
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"CnJhd19kZi5jcmVhdGVPclJlcGxhY2VUZW1wVmlldygiY3VyYXRlZF90cmFuc2FjdGlvbnMiKQpkZjEgPSBzcGFyay5zcWwoIlNFTEVDVCB0eXBlLCBDT1VOVCgqKSBBUyBjb3VudCBGUk9NIGN1cmF0ZWRfdHJhbnNhY3Rpb25zIEdST1VQIEJZIHR5cGUiKQpkaXNwbGF5KGRmMSkgICMgY2hvb3NlIHNpbmdsZSBudW1iZXIgb3IgYmFyCg==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView2ac8740\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView2ac8740\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView2ac8740\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView2ac8740) SELECT `type`,SUM(`count`) `column_b8a7fff2118` FROM q GROUP BY `type`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView2ac8740\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "type",
             "id": "column_b8a7fff2117"
            },
            "y": [
             {
              "column": "count",
              "id": "column_b8a7fff2118",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_b8a7fff2118": {
             "name": "count",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "a7f5e87c-53c3-4077-bb30-5099b2a31ce5",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 15.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "type",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "type",
           "type": "column"
          },
          {
           "alias": "column_b8a7fff2118",
           "args": [
            {
             "column": "count",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "raw_df.createOrReplaceTempView(\"curated_transactions\")\n",
    "df1 = spark.sql(\"SELECT type, COUNT(*) AS count FROM curated_transactions GROUP BY type\")\n",
    "display(df1)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d56d07bb-f70e-4bc5-bab5-2d3dba8acdbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Total Amount Transacted per Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79fa2572-5276-4dc3-ae49-2b611393b673",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>type</th><th>total_amount</th></tr></thead><tbody><tr><td>TRANSFER</td><td>5.503643567413E10</td></tr><tr><td>CASH_IN</td><td>3.859475828889E10</td></tr><tr><td>CASH_OUT</td><td>6.876473738324E10</td></tr><tr><td>PAYMENT</td><td>3.93609652216E9</td></tr><tr><td>DEBIT</td><td>4.219599495E7</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "TRANSFER",
         5.503643567413E10
        ],
        [
         "CASH_IN",
         3.859475828889E10
        ],
        [
         "CASH_OUT",
         6.876473738324E10
        ],
        [
         "PAYMENT",
         3.93609652216E9
        ],
        [
         "DEBIT",
         4.219599495E7
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_amount",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGYzID0gc3Bhcmsuc3FsKCJTRUxFQ1QgdHlwZSwgUk9VTkQoU1VNKGFtb3VudCksIDIpIEFTIHRvdGFsX2Ftb3VudCBGUk9NIGN1cmF0ZWRfdHJhbnNhY3Rpb25zIEdST1VQIEJZIHR5cGUiKQpkaXNwbGF5KGRmMykgIAo=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView452123e\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView452123e\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView452123e\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView452123e) SELECT `type`,SUM(`total_amount`) `column_b8a7fff2127` FROM q GROUP BY `type`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView452123e\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "type",
             "id": "column_b8a7fff2126"
            },
            "y": [
             {
              "column": "total_amount",
              "id": "column_b8a7fff2127",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_b8a7fff2127": {
             "color": "#00B6EB",
             "name": "total_amount",
             "type": "column",
             "yAxis": 0
            },
            "total_amount": {
             "name": "total_amount",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "e474d2d6-6b53-4465-a444-385c6a3f25b2",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 16.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "type",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "type",
           "type": "column"
          },
          {
           "alias": "column_b8a7fff2127",
           "args": [
            {
             "column": "total_amount",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = spark.sql(\"SELECT type, ROUND(SUM(amount), 2) AS total_amount FROM curated_transactions GROUP BY type\")\n",
    "display(df3)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d811a51-75d6-4ef3-8bfd-2c1ec7b82992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.Fraud Detection Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992162ca-f913-454a-89bc-de58e25576ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>type</th><th>total</th><th>total_frauds</th></tr></thead><tbody><tr><td>TRANSFER</td><td>86753</td><td>564</td></tr><tr><td>CASH_IN</td><td>227130</td><td>0</td></tr><tr><td>CASH_OUT</td><td>373641</td><td>578</td></tr><tr><td>PAYMENT</td><td>353873</td><td>0</td></tr><tr><td>DEBIT</td><td>7178</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "TRANSFER",
         86753,
         564
        ],
        [
         "CASH_IN",
         227130,
         0
        ],
        [
         "CASH_OUT",
         373641,
         578
        ],
        [
         "PAYMENT",
         353873,
         0
        ],
        [
         "DEBIT",
         7178,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_frauds",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGY0ID0gc3Bhcmsuc3FsKCIiIgpTRUxFQ1QgdHlwZSwgCiAgICAgICBDT1VOVCgqKSBBUyB0b3RhbCwgCiAgICAgICBTVU0oQ0FTRSBXSEVOIGlzRnJhdWQ9MSBUSEVOIDEgRUxTRSAwIEVORCkgQVMgdG90YWxfZnJhdWRzCkZST00gY3VyYXRlZF90cmFuc2FjdGlvbnMKR1JPVVAgQlkgdHlwZQoiIiIpCmRpc3BsYXkoZGY0KSAgCg==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView4aea00e\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView4aea00e\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView4aea00e\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView4aea00e) SELECT `total`,SUM(`total_frauds`) `column_b8a7fff2142`,`type` FROM q GROUP BY `total`,`type`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView4aea00e\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "type",
             "id": "column_b8a7fff2143"
            },
            "x": {
             "column": "total",
             "id": "column_b8a7fff2141"
            },
            "y": [
             {
              "column": "total_frauds",
              "id": "column_b8a7fff2142",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_b8a7fff2142": {
             "name": "total_frauds",
             "type": "column",
             "yAxis": 0
            },
            "total_frauds": {
             "name": "total_frauds",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "6e05ee2d-afbc-473a-8076-f5b866b30d95",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 17.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "total",
           "type": "column"
          },
          {
           "column": "type",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "total",
           "type": "column"
          },
          {
           "alias": "column_b8a7fff2142",
           "args": [
            {
             "column": "total_frauds",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "column": "type",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df4 = spark.sql(\"\"\"\n",
    "SELECT type, \n",
    "       COUNT(*) AS total, \n",
    "       SUM(CASE WHEN isFraud=1 THEN 1 ELSE 0 END) AS total_frauds\n",
    "FROM curated_transactions\n",
    "GROUP BY type\n",
    "\"\"\")\n",
    "display(df4)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3c0c40b-d773-4e04-a008-36a648e06d1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Final Conclusion\n",
    "This project involved analyzing a large-scale financial transaction dataset using Spark SQL and PySpark on Databricks to uncover insights related to fraud detection. The analysis revealed key patterns:\n",
    "\n",
    "CASH_OUT and TRANSFER transactions dominate both in volume and value, making them critical areas for monitoring.\n",
    "\n",
    "Fraudulent activities are exclusively found in TRANSFER and CASH_OUT transactions, pointing to specific vulnerabilities in these types.\n",
    "\n",
    "The current fraud detection system flagged zero fraudulent transactions, while 1,142 actual frauds were identified, indicating a complete failure of the fraud flagging mechanism.\n",
    "\n",
    "High-value frauds are concentrated in TRANSFER transactions, including some in the range of 10 million units, which is alarming.\n",
    "\n",
    "Account balance anomalies were found where funds were debited from the origin but not credited to the destination, especially in fraudulent cases — signaling suspicious manipulations.\n",
    "\n",
    "This analysis demonstrates the power of Spark-based data engineering pipelines and how they can be used to uncover weaknesses in fraud detection systems. The project simulates an end-to-end data pipeline from raw to cleansed to curated layers, followed by business insights visualization — preparing the foundation for deploying fraud detection ML models in future work."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bank_project_new",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}